{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project\n",
    "\n",
    "## Goals\n",
    "\n",
    "Write an agglomerative clustering algorithm for Reddit data. \n",
    "\n",
    "## Packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data= pd.read_csv('medoutput.csv')\n",
    "subset_data= pd.read_csv('subset_medoutput.csv')\n",
    "\n",
    "freqs=data.loc[:,list(set(data.columns) - set(('subreddit','count(1)','sum(wordcount)')))]\n",
    "subset_freqs=subset_data.loc[:,list(set(data.columns) - set(('subreddit','count(1)','sum(wordcount)')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    v2=vector\n",
    "    vmin=float(min(vector))\n",
    "    vmax=float(max(vector))\n",
    "    vrange=vmax-vmin\n",
    "\n",
    "#    print('vector', vector, vrange)\n",
    "    \n",
    "    l=len(vector)\n",
    "    for i in range(0,l):\n",
    "        dif=float(vector[i])-vmin\n",
    "#        print('dif',dif, vrange, dif/vrange)\n",
    "        v2[i]=dif/vrange\n",
    "#        print(vector[i])\n",
    "    return v2\n",
    "\n",
    "def normalizeall(df):\n",
    "    df2=df\n",
    "    i=df.shape[1]\n",
    "    for j in range(0,i):\n",
    "        df2[:,j]=normalize(df2[:,j])\n",
    "    return df2\n",
    "\n",
    "nfreqs=normalizeall(np.array(freqs))\n",
    "nsubset_freqs=normalizeall(np.array(subset_freqs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By hand Algorithm\n",
    "\n",
    "Need: Distance between points (Euclidean for now) outout= matrix, Distance between Clusters (average distance between points in each cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointDistance (point1, point2):\n",
    "    dimNum=len(point1)\n",
    "    if dimNum!=len(point2):\n",
    "        print(\"we have a dimensionality problem, Houston\")\n",
    "    \n",
    "    s=0\n",
    "    \n",
    "    for dim in range(0,dimNum):\n",
    "        dif=float(point1[dim])-float(point2[dim])\n",
    "        difSq=dif**2\n",
    "        s+=difSq\n",
    "    return np.sqrt(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.78132376 1.81191651 ... 2.03821499 1.45283565 1.03570369]\n",
      " [1.78132376 0.         1.00017455 ... 1.20854604 1.67657719 1.20093622]\n",
      " [1.81191651 1.00017455 0.         ... 1.29327809 1.6736862  1.34511947]\n",
      " ...\n",
      " [2.03821499 1.20854604 1.29327809 ... 0.         2.06879097 1.60721036]\n",
      " [1.45283565 1.67657719 1.6736862  ... 2.06879097 0.         1.34928867]\n",
      " [1.03570369 1.20093622 1.34511947 ... 1.60721036 1.34928867 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data=nsubset_freqs\n",
    "n=np.shape(data)[0]\n",
    "d=np.shape(data)[1]\n",
    "\n",
    "distanceMatrix=np.zeros((n,n))\n",
    "\n",
    "for i in range(0,n):\n",
    "    pointa = data[i,]\n",
    "    for j in range(0,n):\n",
    "        pointb = data[j,] \n",
    "        distanceMatrix[i][j]=pointDistance(pointa, pointb)\n",
    "print(distanceMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AgglomerativeClustering(n_clusters=5, affinity='euclidean', memory='cacheing/', \n",
    "                        connectivity=None, \n",
    "                        compute_full_tree='auto', \n",
    "                        linkage='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty for running one liners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(freqs)\n",
    "#plt.figure()\n",
    "#plt.axes([0, 0, 1, 1])\n",
    "#for l, c in zip(np.arange(model.n_clusters), 'rgbk'):\n",
    "#    plt.plot(freqs[model.labels_ == l].T, c=c, alpha=.5)\n",
    "#plt.axis('tight')\n",
    "#plt.axis('off')\n",
    "#plt.suptitle(\"AgglomerativeClustering(affinity=%s)\" % 'euclidean', size=20)\n",
    "\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_rat=np.zeros(66)\n",
    "change=np.zeros(66)\n",
    "\n",
    "for componentsN in range(65,0,-1):\n",
    "    pca=PCA(n_components=componentsN)\n",
    "    pca.fit(nfreqs)\n",
    "#    print(\"components\",componentsN)\n",
    "#    print(\"explained variance\", pca.explained_variance_ratio_)\n",
    "#    print(\" sum explained variance\", sum(pca.explained_variance_ratio_))\n",
    "    exp_var_rat[componentsN-1]=sum(pca.explained_variance_ratio_)\n",
    "    change[componentsN-1]=exp_var_rat[componentsN]-exp_var_rat[componentsN-1]\n",
    "print(exp_var_rat)\n",
    "#print(change)\n",
    "\n",
    "\n",
    "plt.plot(exp_var_rat[:64])\n",
    "plt.plot(change[:64])\n",
    "                \n",
    "exp_var_rat[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyperC=21\n",
    "dimlabellist=['d1','d2','d3','d4','d5','d6','d7','d8','d9','d10','d11','d12','d13','d14','d15','d16','d17','d18','d19','d20','d21']\n",
    "pca=PCA(n_components=hyperC)\n",
    "nred_data=pca.fit_transform(nfreqs)\n",
    "numnfreqs=np.array(nfreqs)\n",
    "\n",
    "'''#10*65 version\n",
    "cov=np.zeros((10,65))\n",
    "for od in range (0,65):\n",
    "    #print(od, nfreqs[:,od])\n",
    "    for pc in range (0,10):\n",
    "        #print(pc,red_data[:,pc])\n",
    "        cov[pc,od]=np.correlate(nfreqs[:,od],red_data[:,pc])\n",
    "cov=pd.DataFrame(cov,columns=list(freqs))\n",
    "print(cov)\n",
    "'''\n",
    "\n",
    "#65*10 version\n",
    "\n",
    "cov=np.zeros((65,hyperC))\n",
    "\n",
    "for od in range (0,65):\n",
    "    #print(od, nfreqs[:,od])\n",
    "    for pc in range (0,hyperC):\n",
    "        #print(pc,red_data[:,pc])\n",
    "        cov[od,pc]=np.correlate(numnfreqs[:,od],nred_data[:,pc])\n",
    "        \n",
    "cov=pd.DataFrame(cov,index=list(freqs),columns=dimlabellist)\n",
    "\n",
    "abscov=abs(cov)\n",
    "\n",
    "#abscov.sort_values(by=['d11'],ascending=False)\n",
    "\n",
    "#for column in abscov.columns:\n",
    "#    print(column)\n",
    "#    print(abscov.sort_values(by=column,ascending=False).head(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperC=21\n",
    "\n",
    "pca=PCA(n_components=hyperC)\n",
    "nred_subdata=pca.fit_transform(nsubset_freqs)\n",
    "nsfreqs=np.array(nsubset_freqs)\n",
    "\n",
    "\n",
    "pd.DataFrame(nsubset_freqs, columns=list(freqs), index=subset_data['subreddit']).to_csv('normal_subset_freqs.csv')\n",
    "pd.DataFrame(nred_subdata,columns=dimlabellist).to_csv('reduced_normal_subset_freqs')\n",
    "\n",
    "\n",
    "'''#10*65 version\n",
    "cov=np.zeros((10,65))\n",
    "for od in range (0,65):\n",
    "    #print(od, nfreqs[:,od])\n",
    "    for pc in range (0,10):\n",
    "        #print(pc,red_data[:,pc])\n",
    "        cov[pc,od]=np.correlate(nfreqs[:,od],red_data[:,pc])\n",
    "cov=pd.DataFrame(cov,columns=list(freqs))\n",
    "print(cov)\n",
    "'''\n",
    "\n",
    "#65*10 version\n",
    "\n",
    "cov=np.zeros((65,hyperC))\n",
    "\n",
    "for od in range (0,65):\n",
    "    #print(od, nfreqs[:,od])\n",
    "    for pc in range (0,hyperC):\n",
    "        #print(pc,red_data[:,pc])\n",
    "        cov[od,pc]=np.correlate(nsfreqs[:,od],nred_subdata[:,pc])\n",
    "cov=pd.DataFrame(cov,index=list(subset_freqs),columns=dimlabellist,)\n",
    "\n",
    "abscov=abs(cov)\n",
    "\n",
    "abscov.to_csv('subset_covariance.csv')\n",
    "\n",
    "#for column in abscov.columns:\n",
    "#    print(column)\n",
    "#    print(abscov.sort_values(by=column,ascending=False).head(15).index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abscov.sort_values(by='d1') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans on PCA\n",
    "### larger daatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyper=25\n",
    "\n",
    "cluster_score=np.zeros(hyper)\n",
    "change=np.zeros(hyper)\n",
    "\n",
    "for clustersN in range(hyper,0,-1):\n",
    "    kmeans=KMeans(n_clusters=clustersN)\n",
    "    kmeans.fit(nred_data)\n",
    "    cluster_score[clustersN-1]=kmeans.score(nred_data)\n",
    "    change[clustersN-2]=cluster_score[clustersN-1]-cluster_score[clustersN-2]\n",
    "\n",
    "print(cluster_score)\n",
    "\n",
    "print(change)\n",
    "plt.plot(cluster_score)\n",
    "plt.plot(change[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperC=7\n",
    "kmeans=KMeans(n_clusters=hyperC)\n",
    "\n",
    "predictions=kmeans.fit_predict(nred_data)\n",
    "\n",
    "kmeans.score(nred_data)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "\n",
    "data['cluster']=predictions\n",
    "\n",
    "clabels= []\n",
    "\n",
    "for c in range(0,hyperC):\n",
    "    #print(c,'\\n') \n",
    "    #print(kmeans.cluster_centers_[c])\n",
    "    clabels.append(str(list(data[data['cluster']==c].sort_values(by='count(1)').tail(10)['subreddit'])))\n",
    "\n",
    "print(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=pd.DataFrame(kmeans.cluster_centers_,index=clabels, columns=dimlabellist)\n",
    "centers.to_csv('centers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smaller data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperC=15\n",
    "kmeans=KMeans(n_clusters=hyperC)\n",
    "\n",
    "spredictions=kmeans.fit_predict(nred_subdata)\n",
    "\n",
    "kmeans.score(nred_subdata)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "\n",
    "subset_data['cluster']=spredictions\n",
    "\n",
    "clabels= []\n",
    "\n",
    "for c in range(0,hyperC):\n",
    "    #print(c,'\\n') \n",
    "    #print(kmeans.cluster_centers_[c])\n",
    "    clabels.append(str(list(subset_data[subset_data['cluster']==c].sort_values(by='count(1)').tail(10)['subreddit'])))\n",
    "\n",
    "print(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=pd.DataFrame(kmeans.cluster_centers_,index=clabels, columns=dimlabellist)\n",
    "centers.to_csv('subsetcenters.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
